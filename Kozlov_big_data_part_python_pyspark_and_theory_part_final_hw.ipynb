{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Практика Python**\n",
        "\n",
        "ratings: https://drive.google.com/file/d/1Rd5_Hsc59vzxgzfTubkPsfMUmYZZZN8z/view?usp=drive_link\n",
        "\n",
        "movies: https://drive.google.com/file/d/1GJsbt-o6k4cbPqTImQ-z5NLA6RXpiaWg/view?usp=drive_link"
      ],
      "metadata": {
        "id": "T9lGL3PJTcBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Для использования from_pandas нужно установить версию pyspark >= 3.2\n",
        "# pip install pyspark\n",
        "# import pyspark.pandas as ps"
      ],
      "metadata": {
        "id": "tQ6TDmmbZnVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8GOBCFte7ls"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environmental variables\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "viJPwdxMfvVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading required libraries\n",
        "import findspark\n",
        "import re\n",
        "findspark.init()\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.types import StringType, DateType, FloatType\n",
        "import datetime as dt\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from pandas.api.types import is_int64_dtype\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "6nJtjJUefxk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузите в колаб файлы по оценкам (ratings) и фильмам (movies) и\n",
        "# создайте на их основе pandas-датафреймы\n",
        "# movies_url = 'https://drive.google.com/uc?id=' + 'https://drive.google.com/file/d/1GJsbt-o6k4cbPqTImQ-z5NLA6RXpiaWg/view?usp=drive_link'.split('/')[-2]\n",
        "# ratings_url = 'https://drive.google.com/uc?id=' + 'https://drive.google.com/file/d/1Rd5_Hsc59vzxgzfTubkPsfMUmYZZZN8z/view?usp=drive_link'.split('/')[-2]\n",
        "\n",
        "movies = pd.read_csv('u.item.csv', encoding= 'unicode_escape', sep= '|',\n",
        "                     names= ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
        "                             'unknown', 'Action', 'Adventure', 'Animation', 'Children_s', 'Comedy', 'Crime',\n",
        "                             'Documentary', 'Drama', 'Fantasy', 'Film_Noir', 'Horror', 'Musical', 'Mystery',\n",
        "                             'Romance', 'Sci_Fi', 'Thriller', 'War', 'Western'])\n",
        "ratings = pd.read_csv('u.data.csv', sep= '\\t', names= ['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit= 's')"
      ],
      "metadata": {
        "id": "qiALdpZygDFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Средствами Pandas, используя dataframe ratings, найдите id пользователя,\n",
        "# поставившего больше всего оценок\n",
        "top1 = ratings.groupby('user_id')[['rating']].count().\\\n",
        "    sort_values(by= 'rating', ascending= False).reset_index()\n",
        "print(f'пользователь с id {top1.iloc[0, 0]} поставившил больше всего оценок - {top1.iloc[0, 1]}')"
      ],
      "metadata": {
        "id": "yITMO7YWlrhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оставьте в датафрейме ratings только те фильмы, который оценил данный пользователь\n",
        "ratings.loc[ratings['user_id'] == top1.iloc[0, 0]]"
      ],
      "metadata": {
        "id": "YeKyxFxeZW2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавьте к датафрейму из задания 3 столбцы: По жанрам. Каждый столбец - это жанр. Единицу записываем, если фильм принадлежит данному жанру и 0 - если нет\n",
        "merged_df = ratings.merge(movies, how= 'inner', left_on= 'item_id', right_on= 'movie_id').drop(columns= ['item_id', 'video_release_date'])\n",
        "top1_films = merged_df.loc[merged_df['user_id'] == top1.iloc[0, 0]]\n",
        "print(f'rows: {top1_films.shape[0]}\\ncolumns: {top1_films.shape[1]}')\n",
        "top1_films.head()"
      ],
      "metadata": {
        "id": "lGvqV3RMfGbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# столбцы с общим количеством оценок от всех пользователей на фильм и суммарной оценкой от всех пользователей\n",
        "main_df = merged_df.groupby('movie_id').agg({'rating': ['count', 'sum']})['rating'].merge(top1_films, how= 'inner', on= ['movie_id'])\n",
        "main_df['release_year'] = pd.to_datetime(main_df['release_date']).dt.year\n",
        "main_df.head()"
      ],
      "metadata": {
        "id": "6VSfsMDgh2Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сформируйте X_train, X_test, y_train, y_test\n",
        "x = main_df.drop(columns= ['movie_id', 'user_id', 'rating', 'timestamp', 'movie_title', 'release_date', 'IMDb_URL'])\n",
        "y = main_df['rating']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state= 13, stratify= y, test_size= .2)"
      ],
      "metadata": {
        "id": "Pk_KbWDWwcso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Возьмите модель линейной регрессии (или любую другую для задачи регрессии) и обучите ее на фильмах\n",
        "\n",
        "# Модель линейного дискриминантного анализа (ЛДА)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(x_train, y_train)\n",
        "print(classification_report(y_test, lda.predict(x_test)))"
      ],
      "metadata": {
        "id": "wo-dgfuu2mIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация результатов обученной модели ЛДА, полученных на тестовой выборке\n",
        "predictions = lda.predict(x_test)\n",
        "cm = confusion_matrix(y_test, predictions, labels= lda.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix= cm,\n",
        "                              display_labels= lda.classes_)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ibeWnWVoUg8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель логистической регресии\n",
        "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(multi_class= 'multinomial'))\n",
        "pipe_lr.fit(x_train, y_train)\n",
        "print(classification_report(y_test, pipe_lr.predict(x_test)))"
      ],
      "metadata": {
        "id": "yhBh63KDdwKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация результатов обученной модели логистической регрессии, полученных на тестовой выборке\n",
        "predictions_lr = pipe_lr.predict(x_test)\n",
        "cm_lr = confusion_matrix(y_test, predictions_lr, labels= pipe_lr.classes_)\n",
        "disp_lr = ConfusionMatrixDisplay(confusion_matrix= cm_lr,\n",
        "                                 display_labels= pipe_lr.classes_)\n",
        "\n",
        "disp_lr.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QD26PnX9fovc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель линейного дискриминантного анализа (ЛДА), с масштабированием\n",
        "pipe_lda = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis())\n",
        "pipe_lda.fit(x_train, y_train)\n",
        "print(classification_report(y_test, pipe_lda.predict(x_test)))"
      ],
      "metadata": {
        "id": "EZV7g1tUgF8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация результатов обученной модели ЛДА, полученных на тестовой выборке, с масштабированием\n",
        "predictions_lda = pipe_lda.predict(x_test)\n",
        "cm_lda = confusion_matrix(y_test, predictions_lda, labels= pipe_lda.classes_)\n",
        "disp_lda = ConfusionMatrixDisplay(confusion_matrix= cm_lda,\n",
        "                                  display_labels= pipe_lda.classes_)\n",
        "\n",
        "disp_lda.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hw61UkHBg5uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель линейной регрессии (для доп сравнения)\n",
        "linr = LinearRegression()\n",
        "linr.fit(x_train, y_train)\n",
        "predictions_linr = linr.predict(x_test)"
      ],
      "metadata": {
        "id": "koqjlAtbYgSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Диаграмма рассеяния для результатов прогноза по линейной регрессии\n",
        "plt.scatter(y_test, predictions_linr)\n",
        "plt.ylabel('Прогнозы')\n",
        "plt.xlabel('Факт')\n",
        "plt.title('Диаграмма рассеяния прогнозных и фактических значений')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xg8UysAhahCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Метрики точности модели линейной регрессии\n",
        "print(f'R2: {metrics.r2_score(y_test, predictions_linr).round(3)}')\n",
        "print(f'MAE: {metrics.mean_absolute_error(y_test, predictions_linr).round(3)}')\n",
        "print(f'MSE: {metrics.mean_squared_error(y_test, predictions_linr).round(3)}')\n",
        "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, predictions_linr)).round(3)}')\n",
        "\n",
        "sns.histplot((y_test - predictions_linr), kde= True)\n",
        "plt.title('Плотность распределения остатков линейной модели')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2zSx_fDa4pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                             ||\n",
        "#                             \\/\n",
        "# Для задач, в которых количество уникальных значений исследуемой переменной меньше 5-7, необходимо использовать алгоритмы классификации"
      ],
      "metadata": {
        "id": "3Ujbg-yXbG_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузить данные в spark\n",
        "# movies\n",
        "movies_spark = spark.read.csv('u.item.csv', inferSchema= True, sep= '|').toDF(\n",
        "    'movie_id', 'movie_title', 'release_date', 'video_release_date',\n",
        "    'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children_s\",\n",
        "    'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film_Noir',\n",
        "    'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Thriller', 'War',\n",
        "    'Western'\n",
        ").drop(\n",
        "    'video_release_date'\n",
        ")\n",
        "\n",
        "# ratings\n",
        "ratings_spark = spark.read.csv('u.data.csv', inferSchema= True, sep= '\\t').toDF(\n",
        "    'user_id', 'item_id', 'rating', 'timestamp'\n",
        ").withColumn(\n",
        "      'timestamp', from_unixtime(col('timestamp'), 'MM-dd-yyyy HH:mm:ss')\n",
        ")"
      ],
      "metadata": {
        "id": "B9YvEYP8bxH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Для использования from_pandas нужно установить версию pyspark >= 3.2\n",
        "# pip install pyspark\n",
        "# import pyspark.pandas as ps"
      ],
      "metadata": {
        "id": "WLCpgH05WQMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movies_spark = ps.from_pandas(movies)\n",
        "# movies_spark"
      ],
      "metadata": {
        "id": "-gzULgyzYKK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mpVM6bF7YPkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df_spark = ratings_spark.join(movies_spark,\n",
        "                                     ratings_spark['item_id'] == movies_spark['movie_id'],\n",
        "                                     'inner').drop('item_id')\n",
        "\n",
        "print((merged_df_spark.count(), len(merged_df_spark.columns)))\n",
        "merged_df_spark.show()"
      ],
      "metadata": {
        "id": "CAAhnD6_ehe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Средствами спарка вывести среднюю оценку для каждого фильма\n",
        "mean_rating_by_movie = merged_df_spark.groupBy('movie_id').agg(\n",
        "    round(avg('rating'), 2)\n",
        ").withColumnRenamed(\n",
        "    'round(avg(rating), 2)', 'mean_rating'\n",
        ").sort(\n",
        "    'mean_rating', ascending= False\n",
        ")\n",
        "\n",
        "print((mean_rating_by_movie.count(), len(mean_rating_by_movie.columns)))\n",
        "mean_rating_by_movie.show()"
      ],
      "metadata": {
        "id": "jId1vfFYf6kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитайте средствами спарка среднюю оценку для каждого жанра\n",
        "df_ratings_spark = merged_df_spark.drop('user_id', 'timestamp', 'movie_id', 'movie_title', 'release_date', 'IMDb_URL')\n",
        "genres = [\n",
        "    'unknown', 'Action', 'Adventure', 'Animation', 'Children_s', 'Comedy',\n",
        "    'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film_Noir', 'Horror',\n",
        "    'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Thriller', 'War', 'Western'\n",
        "]\n",
        "genre_cols_expr = ', '.join([f\"'{i}', {i}\" for i in genres])\n",
        "df_transformed = df_ratings_spark.selectExpr('rating', f'stack(19, {genre_cols_expr}) as (genre, is_genre)')\n",
        "\n",
        "result_spark = df_transformed.filter(col('is_genre') == 1)\n",
        "\n",
        "print((result_spark.count(), len(result_spark.columns)))\n",
        "result_spark.groupBy('genre').agg(\n",
        "    round(avg('rating'), 2)\n",
        ").withColumnRenamed(\n",
        "    'round(avg(rating), 2)', 'mean_rating'\n",
        ").sort(\n",
        "    'mean_rating', ascending= False\n",
        ").show()"
      ],
      "metadata": {
        "id": "iwtr1_RZkiNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка решения в pandas\n",
        "merged_df = ratings.merge(movies, how= 'inner', left_on= 'item_id', right_on= 'movie_id').drop(columns= ['item_id', 'video_release_date'])\n",
        "genres = merged_df.drop(columns= ['user_id', 'timestamp', 'movie_id', 'movie_title', 'release_date', 'IMDb_URL'])\n",
        "\n",
        "df_melted = genres.melt(id_vars= 'rating', var_name= 'genre', value_name= 'is_genre')\n",
        "result = df_melted[df_melted['is_genre'] == 1]\n",
        "result.reset_index(drop= True, inplace= True)\n",
        "\n",
        "print(result.shape)\n",
        "result.groupby('genre')[['rating']].mean().sort_values(by= 'rating', ascending= False).round(2).rename(columns= {'rating': 'mean_rating'})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4PwbUssIjNG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# В спарке получить 2 датафрейма с 5-ю самыми популярными и самыми непопулярными фильмами (по количеству оценок, либо по самой оценке - на Ваш выбор)\n",
        "top_df_spark = merged_df_spark.groupBy('movie_id', 'movie_title').agg(\n",
        "    count('rating')\n",
        ").withColumnRenamed(\n",
        "    'count(rating)', 'count_rating'\n",
        ")"
      ],
      "metadata": {
        "id": "9kpqYLkXtQ2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Топ 5 самых популярных фильмов по количеству оценок\n",
        "print((top_df_spark.count(), len(top_df_spark.columns)))\n",
        "top_df_spark.sort(\n",
        "    desc('count_rating')\n",
        ").show(5)"
      ],
      "metadata": {
        "id": "kOTK7OQph6KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Топ 5 самых непопулярных фильмов по количеству оценок\n",
        "print((top_df_spark.count(), len(top_df_spark.columns)))\n",
        "top_df_spark.sort(\n",
        "    asc('count_rating')\n",
        ").show(5)"
      ],
      "metadata": {
        "id": "4wwYweoqh69U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Теоретическая часть**"
      ],
      "metadata": {
        "id": "sp-GXTXjvweT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Задание 1: Описать основные бизнес-отчеты (2-3 штуки), которые мы хотим видеть по нашему бизнесу***\n",
        "\n",
        "Основные бизнес-отчеты:\n",
        "- Отчет по самым популярным фильмам/сериалам на платформе за определенный период времени\n",
        "- Отчет по среднему времени просмотра контента на платформе пользователем\n",
        "- Отчет по конверсии пользователей из бесплатного пробного периода в платных подписчиков\n",
        "\n",
        "***Задание 2: Описать основные имеющиеся данные и источники их поступления***\n",
        "\n",
        "Основные данные и источники их поступления:\n",
        "- Данные о просмотрах фильмов/сериалов, пользователях, подписках и оплатах на платформе\n",
        "- Данные о контенте, включая название, жанр, длительность и рейтинг\n",
        "- Данные о пользователях, включая их историю просмотров, предпочтения и демографическую информацию\n",
        "\n",
        "***Задание 3: Описать основные сущности в хранилище данных (схема звезда) и процесс заливки данных***\n",
        "\n",
        "Основные сущности в хранилище данных:\n",
        "- Факт: таблица фактов с информацией о просмотрах\n",
        "- Измерения: таблицы с информацией о фильмах, пользователях, подписках, платежах и других связанных сущностях.\n",
        "\n",
        "Процесс заливки данных в хранилище данных включает процессы ETL (извлечение, преобразование, загрузка) для каждой из сущностей и\n",
        "происходит в несколько этапов, которые можно описать следующим образом:\n",
        "\n",
        "- Извлечение данных: на этом этапе происходит извлечение данных из различных источников, таких как базы данных платформы, логи серверов, сторонние сервисы и т.д. Для этого могут использоваться ETL инструменты или написание скриптов для извлечения данных.\n",
        "\n",
        "- Преобразование данных: после извлечения данных необходимо их преобразовать, чтобы они соответствовали структуре целевого хранилища данных. На этом этапе проводится очистка данных от аномалий, заполнение пропущенных значений, изменение форматов данных и другие манипуляции.\n",
        "\n",
        "- Загрузка данных: после преобразования данные загружаются в хранилище данных. Обычно используется модель звезда, где фактовая таблица содержит информацию о событиях (например, просмотры), а измерения содержат информацию о сущностях (например, пользователи, фильмы).\n",
        "\n",
        "- Проверка качества данных: перед загрузкой данных необходимо провести проверку на качество данных. Некоторые из проверок включают проверку на дубликаты записей, наличие обязательных полей, соответствие форматам данных, целостность связей между сущностями и другие.\n",
        "\n",
        "- Мониторинг: после загрузки данных в хранилище важно организовать мониторинг процесса. Это позволяет быстро выявлять проблемы с данными и вносить коррективы в ETL процессы.\n",
        "\n",
        "- Автоматизация: для повышения эффективности и устойчивости процесса заливки данных необходимо автоматизировать его. Это позволит уменьшить вероятность человеческих ошибок и ускорить процесс.\n",
        "\n",
        "***Задание 4: Описать основные проверки на качество данных (10 штук), которыми будем пользоваться при заливке***\n",
        "\n",
        "Основные проверки на качество данных:\n",
        "- Проверка на дубликаты записей\n",
        "- Проверка на наличие обязательных полей\n",
        "- Проверка на аномалии в данных (например, отрицательные значения)\n",
        "- Проверка на соответствие форматам данных (например, дата и время)\n",
        "- Проверка на целостность связей между сущностями\n",
        "- Проверка на наличие выбросов\n",
        "- Проверка на повторяющиеся значения\n",
        "- Проверка на непрерывность последовательности данных\n",
        "- Проверка на соответствие бизнес-правилам\n",
        "- Проверка на уникальность ключевых полей\n",
        "\n",
        "***Задание 5: Придумать Data-проект, который должен улучшить показатели Вашего бизнеса и расписать его по Crisp-DM***\n",
        "\n",
        "Data-проект по улучшению показателей бизнеса:\n",
        "Проект по оптимизации рекомендательной системы для увеличения удержания пользователей.\n",
        "Шаги по Crisp-DM:\n",
        "- Понимание бизнес-проблемы и цели проекта\n",
        "- Изучение и предварительная обработка данных\n",
        "- Построение модели рекомендаций\n",
        "- Тестирование и настройка модели\n",
        "- Разворачивание модели в продакшн\n",
        "- Мониторинг и поддержка модели\n",
        "\n",
        "***Задание 6: Описать требуемые роли в команде по работе с данными на этапах 4 и 5***\n",
        "\n",
        "Требуемые роли в команде:\n",
        "- Data Analyst: для анализа данных и выдачи рекомендаций по улучшению бизнес-показателей\n",
        "- Data Engineer: для разработки и поддержки инфраструктуры данных, ETL процессов и хранилища данных\n",
        "- Data Scientist: для разработки моделей машинного обучения и анализа данных для улучшения рекомендательной системы\n",
        "- Project Manager: для координации и управления проектом по улучшению показателей бизнеса."
      ],
      "metadata": {
        "id": "-iNy1gcxvNLU"
      }
    }
  ]
}